{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!rename -v 's/\\.PNG/\\.png/' *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = './sample_Signature/genuine/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_os = os.listdir(DATADIR)\n",
    "\n",
    "list_no = [str(i).zfill(2)  for i in range(1,31)] \n",
    "\n",
    "list_all = []\n",
    "\n",
    "for i in range(1,31):\n",
    "    a =[] \n",
    "    for j in range(1,6):\n",
    "        str_a = 'NFI-0'+str(i).zfill(2)+'0'+str(j)+'0'+str(i).zfill(2)+'.png'\n",
    "        a.append(DATADIR+str_a)\n",
    "    \n",
    "    list_all.append(a)\n",
    "\n",
    "IMG_SIZE = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 49.09it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 88.91it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 167.45it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 247.77it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 141.17it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 206.92it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 175.34it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 107.54it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 117.83it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 529.69it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 799.22it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 168.76it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 153.28it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 738.85it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 683.89it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 226.76it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 382.99it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 123.32it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 285.25it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 396.04it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 313.91it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  4.75it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 17.98it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 113.37it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 157.14it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 96.17it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 68.03it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 72.29it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 154.86it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 145.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "training_data = []\n",
    "\n",
    "def create_training_data():\n",
    "    for category,j in zip(list_all,list_no):  \n",
    "\n",
    "        #path = os.path.join(DATADIR,category)  # create path to dogs and cats\n",
    "        class_num = j # get the classification  (0 or a 1). 0=dog 1=cat\n",
    "        \n",
    "        for img in tqdm(category):  # iterate over each image per dogs and cats\n",
    "            \n",
    "            img_array = cv2.imread(img ,cv2.IMREAD_GRAYSCALE)  # convert to array\n",
    "            new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # resize to normalize data size\n",
    "            training_data.append([new_array, class_num])  # add this to our training_data\n",
    "\n",
    "\n",
    "create_training_data()\n",
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for features,label in training_data:\n",
    "    X.append(features)\n",
    "    y.append(label)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(X[0].reshape(-1, IMG_SIZE, IMG_SIZE, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for features,label in training_data:\n",
    "    X.append(features)\n",
    "    y.append(label)\n",
    "\n",
    "#print(X[0].reshape(-1, IMG_SIZE, IMG_SIZE, 1))\n",
    "\n",
    "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "y = [int(i) for i in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_labels = to_categorical(y)#, num_classes=30)\n",
    "a = []\n",
    "for i in one_hot_labels:\n",
    "    a.append(i[1:])\n",
    "\n",
    "one_hot_labels = np.asarray(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 30)\n"
     ]
    }
   ],
   "source": [
    "print(one_hot_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 100, 100, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X/255.0\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), input_shape=X.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128))\n",
    "\n",
    "\n",
    "model.add(Dense(30))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "\n",
    "#sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 98, 98, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 98, 98, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 49, 49, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 47, 47, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 47, 47, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 23, 23, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 23, 23, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 33856)             0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 33856)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               4333696   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 30)                3870      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 30)                0         \n",
      "=================================================================\n",
      "Total params: 4,356,382\n",
      "Trainable params: 4,356,382\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 105 samples, validate on 45 samples\n",
      "Epoch 1/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 0.1080 - acc: 0.9714 - val_loss: 0.2668 - val_acc: 0.9667\n",
      "Epoch 2/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0875 - acc: 0.9775 - val_loss: 0.2930 - val_acc: 0.9667\n",
      "Epoch 3/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 0.0774 - acc: 0.9797 - val_loss: 0.3275 - val_acc: 0.9667\n",
      "Epoch 4/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0669 - acc: 0.9803 - val_loss: 0.3525 - val_acc: 0.9667\n",
      "Epoch 5/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0575 - acc: 0.9803 - val_loss: 0.3875 - val_acc: 0.9652\n",
      "Epoch 6/100\n",
      "105/105 [==============================] - 1s 13ms/step - loss: 0.0455 - acc: 0.9810 - val_loss: 0.4300 - val_acc: 0.9548\n",
      "Epoch 7/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 0.0364 - acc: 0.9813 - val_loss: 0.4891 - val_acc: 0.9452\n",
      "Epoch 8/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 0.0295 - acc: 0.9892 - val_loss: 0.5505 - val_acc: 0.9430\n",
      "Epoch 9/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0211 - acc: 0.9927 - val_loss: 0.5799 - val_acc: 0.9415\n",
      "Epoch 10/100\n",
      "105/105 [==============================] - 1s 13ms/step - loss: 0.0140 - acc: 0.9975 - val_loss: 0.6027 - val_acc: 0.9430\n",
      "Epoch 11/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0113 - acc: 0.9975 - val_loss: 0.6160 - val_acc: 0.9437\n",
      "Epoch 12/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0067 - acc: 0.9994 - val_loss: 0.6428 - val_acc: 0.9444\n",
      "Epoch 13/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0052 - acc: 0.9984 - val_loss: 0.6590 - val_acc: 0.9437\n",
      "Epoch 14/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0042 - acc: 0.9994 - val_loss: 0.6699 - val_acc: 0.9437\n",
      "Epoch 15/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0026 - acc: 0.9997 - val_loss: 0.6851 - val_acc: 0.9422\n",
      "Epoch 16/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.6944 - val_acc: 0.9437\n",
      "Epoch 17/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.7046 - val_acc: 0.9437\n",
      "Epoch 18/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.7287 - val_acc: 0.9437\n",
      "Epoch 19/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.7347 - val_acc: 0.9437\n",
      "Epoch 20/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 9.4190e-04 - acc: 1.0000 - val_loss: 0.7394 - val_acc: 0.9437\n",
      "Epoch 21/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 9.0896e-04 - acc: 1.0000 - val_loss: 0.7478 - val_acc: 0.9437\n",
      "Epoch 22/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 6.5985e-04 - acc: 1.0000 - val_loss: 0.7487 - val_acc: 0.9437\n",
      "Epoch 23/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 9.4325e-04 - acc: 0.9997 - val_loss: 0.7566 - val_acc: 0.9422\n",
      "Epoch 24/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 9.8768e-04 - acc: 1.0000 - val_loss: 0.7530 - val_acc: 0.9422\n",
      "Epoch 25/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 8.4185e-04 - acc: 1.0000 - val_loss: 0.7523 - val_acc: 0.9437\n",
      "Epoch 26/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 5.5252e-04 - acc: 1.0000 - val_loss: 0.7534 - val_acc: 0.9437\n",
      "Epoch 27/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 4.8358e-04 - acc: 1.0000 - val_loss: 0.7608 - val_acc: 0.9437\n",
      "Epoch 28/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 4.2622e-04 - acc: 1.0000 - val_loss: 0.7713 - val_acc: 0.9437\n",
      "Epoch 29/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 3.0274e-04 - acc: 1.0000 - val_loss: 0.7807 - val_acc: 0.9437\n",
      "Epoch 30/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 3.2817e-04 - acc: 1.0000 - val_loss: 0.7831 - val_acc: 0.9437\n",
      "Epoch 31/100\n",
      "105/105 [==============================] - 1s 13ms/step - loss: 2.9165e-04 - acc: 1.0000 - val_loss: 0.7878 - val_acc: 0.9430\n",
      "Epoch 32/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 2.5875e-04 - acc: 1.0000 - val_loss: 0.7947 - val_acc: 0.9437\n",
      "Epoch 33/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 5.5558e-04 - acc: 1.0000 - val_loss: 0.7830 - val_acc: 0.9415\n",
      "Epoch 34/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 8.5400e-04 - acc: 1.0000 - val_loss: 0.7322 - val_acc: 0.9407\n",
      "Epoch 35/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.7336 - val_acc: 0.9415\n",
      "Epoch 36/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 7.4761e-04 - acc: 1.0000 - val_loss: 0.7599 - val_acc: 0.9415\n",
      "Epoch 37/100\n",
      "105/105 [==============================] - 1s 14ms/step - loss: 4.1440e-04 - acc: 1.0000 - val_loss: 0.7862 - val_acc: 0.9422\n",
      "Epoch 38/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 2.5979e-04 - acc: 1.0000 - val_loss: 0.7906 - val_acc: 0.9437\n",
      "Epoch 39/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 1.3766e-04 - acc: 1.0000 - val_loss: 0.8022 - val_acc: 0.9430\n",
      "Epoch 40/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 3.2983e-04 - acc: 1.0000 - val_loss: 0.8131 - val_acc: 0.9415\n",
      "Epoch 41/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 2.1311e-04 - acc: 1.0000 - val_loss: 0.8182 - val_acc: 0.9415\n",
      "Epoch 42/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 2.5433e-04 - acc: 1.0000 - val_loss: 0.8229 - val_acc: 0.9430\n",
      "Epoch 43/100\n",
      "105/105 [==============================] - 1s 13ms/step - loss: 1.7275e-04 - acc: 1.0000 - val_loss: 0.8180 - val_acc: 0.9437\n",
      "Epoch 44/100\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.9680e-04 - acc: 1.0000 - val_loss: 0.8276 - val_acc: 0.9437\n",
      "Epoch 45/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 1.1796e-04 - acc: 1.0000 - val_loss: 0.8302 - val_acc: 0.9437\n",
      "Epoch 46/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 1.3094e-04 - acc: 1.0000 - val_loss: 0.8302 - val_acc: 0.9437\n",
      "Epoch 47/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 1.0350e-04 - acc: 1.0000 - val_loss: 0.8291 - val_acc: 0.9437\n",
      "Epoch 48/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 1.0049e-04 - acc: 1.0000 - val_loss: 0.8315 - val_acc: 0.9437\n",
      "Epoch 49/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 8.9457e-05 - acc: 1.0000 - val_loss: 0.8343 - val_acc: 0.9437\n",
      "Epoch 50/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 8.3893e-05 - acc: 1.0000 - val_loss: 0.8386 - val_acc: 0.9437\n",
      "Epoch 51/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 7.7651e-05 - acc: 1.0000 - val_loss: 0.8418 - val_acc: 0.9437\n",
      "Epoch 52/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 9.4831e-05 - acc: 1.0000 - val_loss: 0.8446 - val_acc: 0.9437\n",
      "Epoch 53/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 6.9059e-05 - acc: 1.0000 - val_loss: 0.8468 - val_acc: 0.9437\n",
      "Epoch 54/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 6.6533e-05 - acc: 1.0000 - val_loss: 0.8500 - val_acc: 0.9437\n",
      "Epoch 55/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 5.8200e-05 - acc: 1.0000 - val_loss: 0.8530 - val_acc: 0.9430\n",
      "Epoch 56/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 6.6492e-05 - acc: 1.0000 - val_loss: 0.8535 - val_acc: 0.9430\n",
      "Epoch 57/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 6.5329e-05 - acc: 1.0000 - val_loss: 0.8528 - val_acc: 0.9430\n",
      "Epoch 58/100\n",
      "105/105 [==============================] - 1s 13ms/step - loss: 5.2536e-05 - acc: 1.0000 - val_loss: 0.8531 - val_acc: 0.9430\n",
      "Epoch 59/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 6.4835e-05 - acc: 1.0000 - val_loss: 0.8535 - val_acc: 0.9415\n",
      "Epoch 60/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 5.9647e-05 - acc: 1.0000 - val_loss: 0.8537 - val_acc: 0.9415\n",
      "Epoch 61/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 7.6057e-05 - acc: 1.0000 - val_loss: 0.8542 - val_acc: 0.9437\n",
      "Epoch 62/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 6.1356e-05 - acc: 1.0000 - val_loss: 0.8487 - val_acc: 0.9437\n",
      "Epoch 63/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 8.2442e-05 - acc: 1.0000 - val_loss: 0.8523 - val_acc: 0.9430\n",
      "Epoch 64/100\n",
      "105/105 [==============================] - 1s 13ms/step - loss: 6.6954e-05 - acc: 1.0000 - val_loss: 0.8476 - val_acc: 0.9415\n",
      "Epoch 65/100\n",
      "105/105 [==============================] - 1s 13ms/step - loss: 7.3354e-05 - acc: 1.0000 - val_loss: 0.8445 - val_acc: 0.9415\n",
      "Epoch 66/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 8.9882e-05 - acc: 1.0000 - val_loss: 0.8445 - val_acc: 0.9415\n",
      "Epoch 67/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 7.3211e-05 - acc: 1.0000 - val_loss: 0.8455 - val_acc: 0.9415\n",
      "Epoch 68/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 5.2523e-05 - acc: 1.0000 - val_loss: 0.8455 - val_acc: 0.9430\n",
      "Epoch 69/100\n",
      "105/105 [==============================] - 1s 13ms/step - loss: 7.1053e-05 - acc: 1.0000 - val_loss: 0.8499 - val_acc: 0.9430\n",
      "Epoch 70/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 4.1021e-05 - acc: 1.0000 - val_loss: 0.8539 - val_acc: 0.9430\n",
      "Epoch 71/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 4.6503e-05 - acc: 1.0000 - val_loss: 0.8555 - val_acc: 0.9430\n",
      "Epoch 72/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 4.0551e-05 - acc: 1.0000 - val_loss: 0.8576 - val_acc: 0.9430\n",
      "Epoch 73/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 4.4546e-05 - acc: 1.0000 - val_loss: 0.8580 - val_acc: 0.9437\n",
      "Epoch 74/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 7.7805e-05 - acc: 1.0000 - val_loss: 0.8597 - val_acc: 0.9430\n",
      "Epoch 75/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 9.1108e-05 - acc: 1.0000 - val_loss: 0.8567 - val_acc: 0.9437\n",
      "Epoch 76/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 4.1816e-05 - acc: 1.0000 - val_loss: 0.8554 - val_acc: 0.9430\n",
      "Epoch 77/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 6.3441e-05 - acc: 1.0000 - val_loss: 0.8546 - val_acc: 0.9430\n",
      "Epoch 78/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 5.3960e-05 - acc: 1.0000 - val_loss: 0.8550 - val_acc: 0.9430\n",
      "Epoch 79/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 6.0492e-05 - acc: 1.0000 - val_loss: 0.8541 - val_acc: 0.9430\n",
      "Epoch 80/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 4.0282e-05 - acc: 1.0000 - val_loss: 0.8543 - val_acc: 0.9430\n",
      "Epoch 81/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 5.6796e-05 - acc: 1.0000 - val_loss: 0.8565 - val_acc: 0.9430\n",
      "Epoch 82/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 3.9390e-05 - acc: 1.0000 - val_loss: 0.8589 - val_acc: 0.9430\n",
      "Epoch 83/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 3.5746e-05 - acc: 1.0000 - val_loss: 0.8605 - val_acc: 0.9430\n",
      "Epoch 84/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 3.7748e-05 - acc: 1.0000 - val_loss: 0.8630 - val_acc: 0.9430\n",
      "Epoch 85/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 3.0504e-05 - acc: 1.0000 - val_loss: 0.8640 - val_acc: 0.9430\n",
      "Epoch 86/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 3.8448e-05 - acc: 1.0000 - val_loss: 0.8652 - val_acc: 0.9430\n",
      "Epoch 87/100\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 4.0328e-05 - acc: 1.0000 - val_loss: 0.8674 - val_acc: 0.9430\n",
      "Epoch 88/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 3.0268e-05 - acc: 1.0000 - val_loss: 0.8689 - val_acc: 0.9430\n",
      "Epoch 89/100\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 3.9695e-05 - acc: 1.0000 - val_loss: 0.8698 - val_acc: 0.9430\n",
      "Epoch 90/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 3.6572e-05 - acc: 1.0000 - val_loss: 0.8700 - val_acc: 0.9430\n",
      "Epoch 91/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 2.7334e-05 - acc: 1.0000 - val_loss: 0.8701 - val_acc: 0.9430\n",
      "Epoch 92/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 2.9604e-05 - acc: 1.0000 - val_loss: 0.8699 - val_acc: 0.9430\n",
      "Epoch 93/100\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 5.3174e-05 - acc: 1.0000 - val_loss: 0.8695 - val_acc: 0.9415\n",
      "Epoch 94/100\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 3.7069e-05 - acc: 1.0000 - val_loss: 0.8669 - val_acc: 0.9415\n",
      "Epoch 95/100\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 3.6005e-05 - acc: 1.0000 - val_loss: 0.8657 - val_acc: 0.9415\n",
      "Epoch 96/100\n",
      "105/105 [==============================] - 1s 13ms/step - loss: 4.4049e-05 - acc: 1.0000 - val_loss: 0.8661 - val_acc: 0.9415\n",
      "Epoch 97/100\n",
      "105/105 [==============================] - 1s 14ms/step - loss: 4.2816e-05 - acc: 1.0000 - val_loss: 0.8662 - val_acc: 0.9422\n",
      "Epoch 98/100\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 2.4356e-05 - acc: 1.0000 - val_loss: 0.8665 - val_acc: 0.9430\n",
      "Epoch 99/100\n",
      "105/105 [==============================] - 2s 24ms/step - loss: 2.7681e-05 - acc: 1.0000 - val_loss: 0.8666 - val_acc: 0.9437\n",
      "Epoch 100/100\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 3.3740e-05 - acc: 1.0000 - val_loss: 0.8678 - val_acc: 0.9430\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X, one_hot_labels, batch_size=32, epochs=100, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(filepath):\n",
    "    #IMG_SIZE = 100  # 50 in txt-based\n",
    "    img_array = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)  # read in the image, convert to grayscale\n",
    "    new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # resize image to match model's expected sizing\n",
    "    return new_array.reshape(-1, IMG_SIZE, IMG_SIZE, 1) /255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction2 = model.predict([prepare('./sample_Signature/genuine/NFI-00105001.png')]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0000000e+00 1.0667530e-18 9.4473496e-13 2.3434093e-14 5.6725839e-16\n",
      " 9.0559340e-12 7.4242758e-11 2.6922689e-09 5.2660700e-17 2.0469978e-21\n",
      " 2.7430686e-11 3.5864953e-12 4.9529733e-13 5.2434553e-11 5.0080252e-12\n",
      " 2.1348641e-09 5.9637605e-16 6.2071028e-09 7.1153707e-15 4.9689214e-15\n",
      " 2.0086646e-18 2.1193373e-13 8.3045311e-13 1.7862229e-18 1.4398442e-14\n",
      " 1.6640746e-16 6.3685333e-20 1.9917835e-21 4.9510551e-17 1.1587745e-20]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(prediction2[0])\n",
    "max(prediction2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
